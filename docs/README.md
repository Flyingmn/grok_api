# Camoufox çˆ¬è™«æ¡†æ¶

åŸºäº Camoufox å’Œ Playwright çš„ Python çˆ¬è™«æ¡†æ¶ï¼Œæ”¯æŒå¤šå®ä¾‹ã€å¤šè¿›ç¨‹ã€å¼‚æ­¥æ“ä½œã€‚

## ç‰¹æ€§

- ğŸ¦Š **åŸºäº Camoufox**: ä½¿ç”¨ Camoufox æµè§ˆå™¨ï¼Œæ›´å¥½çš„åæ£€æµ‹èƒ½åŠ›
- ğŸ­ **Playwright é›†æˆ**: å¼ºå¤§çš„æµè§ˆå™¨è‡ªåŠ¨åŒ–åŠŸèƒ½
- ğŸš€ **å¤šå®ä¾‹æ”¯æŒ**: æ”¯æŒåŒæ—¶è¿è¡Œå¤šä¸ªçˆ¬è™«å®ä¾‹
- âš¡ **å¼‚æ­¥/å¤šè¿›ç¨‹**: æ”¯æŒå¼‚æ­¥å’Œå¤šè¿›ç¨‹å¹¶å‘æ‰§è¡Œ
- ğŸ”§ **çµæ´»é…ç½®**: æ”¯æŒæ–‡ä»¶å’Œç¯å¢ƒå˜é‡é…ç½®
- ğŸ“¸ **è‡ªåŠ¨æˆªå›¾**: é”™è¯¯æ—¶è‡ªåŠ¨æˆªå›¾ï¼Œä¾¿äºè°ƒè¯•
- ğŸª **Cookie ç®¡ç†**: è‡ªåŠ¨ä¿å­˜å’ŒåŠ è½½ cookies
- ğŸ“ **è¯¦ç»†æ—¥å¿—**: å®Œæ•´çš„æ—¥å¿—è®°å½•å’Œé”™è¯¯è¿½è¸ª

## å®‰è£…

### æ¨èæ–¹å¼ï¼šä½¿ç”¨Condaç¯å¢ƒï¼ˆæ¨èï¼‰

```bash
# 1. è¿è¡Œè®¾ç½®è„šæœ¬ï¼ˆè‡ªåŠ¨åˆ›å»ºç¯å¢ƒï¼‰
./setup_conda_env.sh

# 2. æ¿€æ´»ç¯å¢ƒ
conda activate camoufox-crawler
# æˆ–ä½¿ç”¨: ./activate_env.sh

# 3. éªŒè¯å®‰è£…
python setup_and_verify.py
```

### æ‰‹åŠ¨å®‰è£…æ–¹å¼

#### 1. åˆ›å»ºCondaç¯å¢ƒ
```bash
# ä½¿ç”¨environment.ymlåˆ›å»ºç¯å¢ƒ
conda env create -f environment.yml

# æ¿€æ´»ç¯å¢ƒ
conda activate camoufox-crawler
```

#### 2. æˆ–è€…åœ¨ç°æœ‰ç¯å¢ƒä¸­å®‰è£…
```bash
# å®‰è£… Camoufox
conda install camoufox

# å®‰è£… Python ä¾èµ–
pip install -r requirements.txt

# å®‰è£… Playwright æµè§ˆå™¨
playwright install firefox
```

## å¿«é€Ÿå¼€å§‹

### 1. å¿«é€Ÿæµ‹è¯•

```bash
# ç¡®ä¿å·²æ¿€æ´»condaç¯å¢ƒ
conda activate camoufox-crawler

# è¿è¡Œå¿«é€Ÿæµ‹è¯•
python quick_test.py
```

è¿™å°†å¯åŠ¨ä¸€ä¸ªç®€å•çš„æµ‹è¯•ï¼Œè®¿é—® Google AI Studio éªŒè¯æ¡†æ¶æ˜¯å¦æ­£å¸¸å·¥ä½œã€‚

### 2. åŸºæœ¬ä½¿ç”¨

```python
import asyncio
from crawler_framework import CrawlerFramework, CrawlerConfig

async def main():
    # åˆ›å»ºæ¡†æ¶å®ä¾‹
    framework = CrawlerFramework()
    
    # åˆ›å»ºé…ç½®
    config = CrawlerConfig()
    config.headless = False  # æœ‰å¤´æ¨¡å¼
    config.timeout = 30000   # 30ç§’è¶…æ—¶
    
    # åˆ›å»ºçˆ¬è™«å®ä¾‹
    instance = framework.create_instance("my_crawler", config)
    
    try:
        # å¯åŠ¨å®ä¾‹
        await instance.start()
        
        # è®¿é—®ç½‘é¡µ
        await instance.goto("https://example.com")
        
        # æˆªå›¾
        await instance.screenshot("example.png")
        
        # ç­‰å¾…å…ƒç´ 
        await instance.wait_for_selector("h1")
        
        # ç‚¹å‡»å…ƒç´ 
        await instance.click("button")
        
        # å¡«å……è¡¨å•
        await instance.fill("input[name='username']", "myuser")
        
    finally:
        # æ¸…ç†èµ„æº
        await framework.close_all()

# è¿è¡Œ
asyncio.run(main())
```

### 3. å¤šå®ä¾‹å¹¶å‘

```python
from multi_runner import MultiRunner, TaskBuilder
from crawler_framework import test_google_ai_studio

async def multi_test():
    # åˆ›å»ºä»»åŠ¡æ„å»ºå™¨
    builder = TaskBuilder()
    
    # æ·»åŠ å¤šä¸ªä»»åŠ¡
    for i in range(3):
        builder.add_task(
            task_id=f"test_{i}",
            function=test_google_ai_studio,
            config={"headless": True}
        )
    
    # è¿è¡Œä»»åŠ¡
    runner = MultiRunner(max_workers=3)
    results = await runner.run_async_tasks(builder.build())
    
    # æŸ¥çœ‹ç»“æœ
    runner.print_results()

asyncio.run(multi_test())
```

## é…ç½®

### ç¯å¢ƒå˜é‡é…ç½®

åˆ›å»º `.env` æ–‡ä»¶ï¼š

```env
# åŸºæœ¬é…ç½®
CRAWLER_MAX_INSTANCES=5
CRAWLER_LOG_LEVEL=INFO
CRAWLER_HEADLESS=false

# æµè§ˆå™¨é…ç½®
CRAWLER_TIMEOUT=30000
CRAWLER_VIEWPORT_WIDTH=1920
CRAWLER_VIEWPORT_HEIGHT=1080
CRAWLER_MAX_RETRIES=3
CRAWLER_RETRY_DELAY=2

# ä»£ç†é…ç½®ï¼ˆå¯é€‰ï¼‰
CRAWLER_PROXY_SERVER=http://proxy.example.com:8080
CRAWLER_PROXY_USERNAME=username
CRAWLER_PROXY_PASSWORD=password

# ç›®å½•é…ç½®
CRAWLER_COOKIES_DIR=cookies
CRAWLER_SCREENSHOTS_DIR=screenshots
CRAWLER_DATA_DIR=data
```

### JSON é…ç½®æ–‡ä»¶

åˆ›å»º `config.json`ï¼š

```json
{
  "max_instances": 5,
  "log_level": "INFO",
  "browser": {
    "headless": false,
    "timeout": 30000,
    "viewport_width": 1920,
    "viewport_height": 1080,
    "max_retries": 3,
    "retry_delay": 2,
    "screenshot_on_error": true
  }
}
```

## é¡¹ç›®ç»“æ„

```
crawler_py/
â”œâ”€â”€ crawler_framework.py    # æ ¸å¿ƒçˆ¬è™«æ¡†æ¶
â”œâ”€â”€ config.py              # é…ç½®ç®¡ç†
â”œâ”€â”€ multi_runner.py        # å¤šè¿›ç¨‹/å¤šçº¿ç¨‹è¿è¡Œå™¨
â”œâ”€â”€ quick_test.py          # å¿«é€Ÿæµ‹è¯•è„šæœ¬
â”œâ”€â”€ setup_conda_env.sh     # Condaç¯å¢ƒè®¾ç½®è„šæœ¬
â”œâ”€â”€ setup_and_verify.py    # ç¯å¢ƒéªŒè¯è„šæœ¬
â”œâ”€â”€ requirements.txt       # Python ä¾èµ–
â”œâ”€â”€ environment.yml        # Condaç¯å¢ƒé…ç½®
â”œâ”€â”€ config.json.example    # é…ç½®æ–‡ä»¶ç¤ºä¾‹
â”œâ”€â”€ CONDA_USAGE.md         # Condaä½¿ç”¨æŒ‡å—
â”œâ”€â”€ activate_env.sh        # ç¯å¢ƒæ¿€æ´»è„šæœ¬(Linux/Mac)
â”œâ”€â”€ activate_env.bat       # ç¯å¢ƒæ¿€æ´»è„šæœ¬(Windows)
â”œâ”€â”€ examples/              # ç¤ºä¾‹ä»£ç 
â”‚   â””â”€â”€ test_google_ai_studio.py
â”œâ”€â”€ logs/                  # æ—¥å¿—ç›®å½•
â”œâ”€â”€ cookies/               # Cookie å­˜å‚¨
â”œâ”€â”€ screenshots/           # æˆªå›¾å­˜å‚¨
â””â”€â”€ data/                  # æ•°æ®å­˜å‚¨
```

## API æ–‡æ¡£

### CrawlerFramework

ä¸»è¦çš„çˆ¬è™«æ¡†æ¶ç±»ã€‚

```python
framework = CrawlerFramework()

# åˆ›å»ºå®ä¾‹
instance = framework.create_instance("instance_id", config)

# å¯åŠ¨å®ä¾‹
await framework.start_instance("instance_id")

# è·å–å®ä¾‹
instance = framework.get_instance("instance_id")

# å…³é—­å®ä¾‹
await framework.close_instance("instance_id")

# å…³é—­æ‰€æœ‰å®ä¾‹
await framework.close_all()
```

### CrawlerInstance

å•ä¸ªçˆ¬è™«å®ä¾‹ã€‚

```python
# å¯åŠ¨å®ä¾‹
await instance.start()

# è®¿é—®ç½‘é¡µ
success = await instance.goto("https://example.com")

# ç­‰å¾…å…ƒç´ 
found = await instance.wait_for_selector("selector")

# ç‚¹å‡»å…ƒç´ 
success = await instance.click("selector")

# å¡«å……æ–‡æœ¬
success = await instance.fill("selector", "text")

# æˆªå›¾
path = await instance.screenshot("filename.png")

# ä¿å­˜ cookies
await instance.save_cookies("cookies.json")

# åŠ è½½ cookies
await instance.load_cookies("cookies.json")

# å…³é—­å®ä¾‹
await instance.close()
```

### MultiRunner

å¤šè¿›ç¨‹/å¤šçº¿ç¨‹è¿è¡Œå™¨ã€‚

```python
runner = MultiRunner(max_workers=3)

# å¼‚æ­¥è¿è¡Œä»»åŠ¡
results = await runner.run_async_tasks(tasks)

# å¤šè¿›ç¨‹è¿è¡Œä»»åŠ¡
results = runner.run_process_tasks(tasks)

# å¤šçº¿ç¨‹è¿è¡Œä»»åŠ¡
results = runner.run_thread_tasks(tasks)

# è·å–ç»“æœæ‘˜è¦
summary = runner.get_results_summary()

# æ‰“å°ç»“æœ
runner.print_results()
```

## ç¤ºä¾‹

### Google AI Studio æµ‹è¯•

```bash
# è¿è¡Œå®Œæ•´æµ‹è¯•ç¤ºä¾‹
python examples/test_google_ai_studio.py
```

è¯¥ç¤ºä¾‹åŒ…å«ï¼š
- ç®€å•è®¿é—®æµ‹è¯•
- ç™»å½•æ£€æµ‹å’Œå¤„ç†
- å¤šå®ä¾‹å¹¶å‘æµ‹è¯•
- ä¸åŒé…ç½®æµ‹è¯•

## æœ€ä½³å®è·µ

### 1. é”™è¯¯å¤„ç†

```python
try:
    await instance.goto("https://example.com")
except Exception as e:
    logger.error(f"è®¿é—®å¤±è´¥: {e}")
    # é”™è¯¯æ—¶ä¼šè‡ªåŠ¨æˆªå›¾ï¼ˆå¦‚æœå¯ç”¨ï¼‰
```

### 2. èµ„æºç®¡ç†

```python
framework = CrawlerFramework()
try:
    # ä½¿ç”¨æ¡†æ¶
    pass
finally:
    # ç¡®ä¿æ¸…ç†èµ„æº
    await framework.close_all()
```

### 3. é…ç½®ç®¡ç†

```python
from config import get_config, get_browser_config

# è·å–å…¨å±€é…ç½®
config = get_config()

# è·å–æµè§ˆå™¨é…ç½®
browser_config = get_browser_config()
```

### 4. å¤šå®ä¾‹ä½¿ç”¨

```python
# ä¸ºä¸åŒç½‘ç«™åˆ›å»ºä¸åŒé…ç½®
config_a = CrawlerConfig()
config_a.timeout = 15000

config_b = CrawlerConfig()
config_b.headless = True
config_b.timeout = 30000

# åˆ›å»ºå¤šä¸ªå®ä¾‹
instance_a = framework.create_instance("site_a", config_a)
instance_b = framework.create_instance("site_b", config_b)
```

## æ•…éšœæ’é™¤

### 1. Camoufox æœªå®‰è£…

```bash
conda install camoufox
```

### 2. Playwright æµè§ˆå™¨æœªå®‰è£…

```bash
playwright install firefox
```

### 3. ä¾èµ–é—®é¢˜

```bash
pip install -r requirements.txt --upgrade
```

### 4. æƒé™é—®é¢˜

ç¡®ä¿æœ‰è¶³å¤Ÿçš„æƒé™åˆ›å»ºç›®å½•å’Œæ–‡ä»¶ã€‚

### 5. ç½‘ç»œé—®é¢˜

æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼Œè€ƒè™‘ä½¿ç”¨ä»£ç†é…ç½®ã€‚

## æ‰©å±•å¼€å‘

### æ·»åŠ æ–°çš„ç½‘ç«™æ”¯æŒ

1. åˆ›å»ºä¸“é—¨çš„ä»»åŠ¡å‡½æ•°ï¼š

```python
async def crawl_my_site(instance: CrawlerInstance, *args):
    # å®ç°å…·ä½“çš„çˆ¬å–é€»è¾‘
    await instance.goto("https://mysite.com")
    # ... æ›´å¤šæ“ä½œ
    return result
```

2. ä½¿ç”¨ TaskBuilder åˆ›å»ºä»»åŠ¡ï¼š

```python
builder = TaskBuilder()
builder.add_task("my_site", crawl_my_site, args=[arg1, arg2])
```

### è‡ªå®šä¹‰é…ç½®

ç»§æ‰¿ CrawlerConfig ç±»æ·»åŠ è‡ªå®šä¹‰é…ç½®ï¼š

```python
class MyConfig(CrawlerConfig):
    def __init__(self):
        super().__init__()
        self.custom_setting = "value"
```

## è®¸å¯è¯

MIT License

## è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼
